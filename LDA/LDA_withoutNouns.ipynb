{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhmnTyTNjyMGxrNq9lR+GP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackCurrantDS/ATiML-Project/blob/master/LDA_withoutNouns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dprEdv1hZL67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVzMOjN_GWfk",
        "colab_type": "code",
        "outputId": "03354fab-51f0-45a5-808d-a950c30ed65d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk; nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-YmUg2SILwg",
        "colab_type": "code",
        "outputId": "5ffbc94b-b2e4-4cd7-ddfe-d0f20630a5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Import Dataset\n",
        "books = pd.read_csv(\"books_withoutNouns.csv\")\n",
        "print(books.genre.unique())\n",
        "books.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sea and Adventure' 'Western Stories' 'Love and Romance'\n",
            " 'Ghost and Horror' 'Humorous and Wit and Satire' 'Literary'\n",
            " 'Detective and Mystery' 'Christmas Stories']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>id</th>\n",
              "      <th>genre</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sea and Adventure</td>\n",
              "      <td>ago narrative reverse previous hound reelingly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sea and Adventure</td>\n",
              "      <td>straight reigned high proper great lofty hills...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Sea and Adventure</td>\n",
              "      <td>sandy lazily inland great grim bustle temporar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Sea and Adventure</td>\n",
              "      <td>wider great upland main single great real fart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Sea and Adventure</td>\n",
              "      <td>medium frequently comparatively rare high true...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               data\n",
              "0           0  ...  ago narrative reverse previous hound reelingly...\n",
              "1           1  ...  straight reigned high proper great lofty hills...\n",
              "2           2  ...  sandy lazily inland great grim bustle temporar...\n",
              "3           3  ...  wider great upland main single great real fart...\n",
              "4           4  ...  medium frequently comparatively rare high true...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuYSLzIXahPt",
        "colab_type": "code",
        "outputId": "0b02cbac-a71d-4909-c854-095d47d4a601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkjK8aPvaAbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#last 5\n",
        "#books['data'] = books['data'].apply(lambda x: str(x)[-100:])\n",
        "#first 5\n",
        "books['data'] = books['data'].apply(lambda x: str(x)[:500])\n",
        "# random 2/3\n",
        "#books['NData'] = books['NData'].apply(lambda x: x[3000:int(len(x)*1/3)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WeKAnRKIp3f",
        "colab_type": "code",
        "outputId": "80420501-34b6-4e82-b7cd-0d32d08abf84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Convert to list\n",
        "data = books.data.values.tolist()\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
        "\n",
        "#print(data[:1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<input>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "<ipython-input-38-ad1f0047730f>:4: DeprecationWarning: invalid escape sequence \\s\n",
            "  data = [re.sub('\\s+', ' ', sent) for sent in data]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8-vevWGwMNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "# Split the documents into tokens.\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "for idx in range(len(data)):\n",
        "    data[idx] = data[idx].lower()  # Convert to lowercase.\n",
        "    data[idx] = tokenizer.tokenize(data[idx])  # Split into words.\n",
        "\n",
        "# Remove numbers, but not words that contain numbers.\n",
        "data = [[token for token in doc if not token.isnumeric()] for doc in data]\n",
        "\n",
        "# Remove words that are only one character.\n",
        "data = [[token for token in doc if len(token) > 1] for doc in data]\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZncsJqtwej3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Lemmatize the documents.\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "data = [[lemmatizer.lemmatize(token) for token in doc] for doc in data]\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdIr1C4FwoFE",
        "colab_type": "code",
        "outputId": "afdf4586-8628-4f76-bcec-07a3d33ccbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\"\"\"\n",
        "# Compute bigrams.\n",
        "from gensim.models import Phrases\n",
        "\n",
        "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
        "bigram = Phrases(data, min_count=20)\n",
        "for idx in range(len(data)):\n",
        "    for token in bigram[data[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            data[idx].append(token)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXH4R21Hw1Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Remove rare and common tokens.\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(data)\n",
        "\n",
        "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
        "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo_nz7Wlw7WU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Bag-of-words representation of the documents.\n",
        "corpus = [dictionary.doc2bow(doc) for doc in data]\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnHGrHrjxA-O",
        "colab_type": "code",
        "outputId": "c0bfbec0-b45d-439e-ffad-d90827079574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens: 236\n",
            "Number of documents: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRC1s0q2IvtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "#print(data_words[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdtCZBC6I0od",
        "colab_type": "code",
        "outputId": "297f660b-2205-4d17-9dc3-0dfd2c13c871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "#print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP9UIvNjI78I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['VERB', 'NOUN', 'PPN']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSNfxo4UJBTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['VERB' , 'PPN'])\n",
        "\n",
        "#print(data_lemmatized[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZMqJcDjxeSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# Make a index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7viBaiGCJNZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPG82yf3JRQj",
        "colab_type": "code",
        "outputId": "53a9c888-a57e-44e5-eb03-6cfc84e3aedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=8, \n",
        "                                           random_state=100,\n",
        "                                            alpha='auto',\n",
        "                                            eta='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8cIoL6wJUHs",
        "colab_type": "code",
        "outputId": "24fb1405-98fa-411f-ff6b-890527df4961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "print(lda_model.print_topics(5))\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(3, '0.041*\"leave\" + 0.041*\"hurt\" + 0.040*\"rag\" + 0.040*\"fall\" + 0.040*\"disappear\" + 0.040*\"annoy\" + 0.040*\"strike\" + 0.040*\"realize\" + 0.040*\"easygoe\" + 0.040*\"gasp\"'), (4, '0.074*\"smix\" + 0.039*\"shipboard\" + 0.039*\"embark\" + 0.039*\"unimagine\" + 0.039*\"unavaile\" + 0.039*\"feel\" + 0.039*\"foul\" + 0.039*\"reverse\" + 0.039*\"stunt\" + 0.039*\"blunt\"'), (5, '0.032*\"admit\" + 0.032*\"bring\" + 0.032*\"disengage\" + 0.032*\"attribute\" + 0.032*\"forgive\" + 0.032*\"object\" + 0.032*\"frighten\" + 0.032*\"intimate\" + 0.032*\"mittene\" + 0.032*\"lewie\"'), (2, '0.032*\"live\" + 0.032*\"leave\" + 0.032*\"close\" + 0.032*\"shake\" + 0.031*\"commonplace\" + 0.031*\"greenmottle\" + 0.031*\"saunter\" + 0.031*\"impassive\" + 0.031*\"unmarrie\" + 0.031*\"rub\"'), (1, '0.051*\"close\" + 0.027*\"smooth\" + 0.027*\"shake\" + 0.027*\"represent\" + 0.027*\"soften\" + 0.027*\"stumble\" + 0.027*\"worry\" + 0.027*\"mean\" + 0.027*\"clasp\" + 0.027*\"charm\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5uxy-bCJYb4",
        "colab_type": "code",
        "outputId": "3d2724f9-47b5-4d55-9143-2a085b11ff5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -5.990979644344814\n",
            "\n",
            "Coherence Score:  0.5547117507790102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A1tWC5LJfxG",
        "colab_type": "code",
        "outputId": "548cc472-8d27-48d7-e889-1244ab25a54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "vis\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1291399460634618563754729534\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1291399460634618563754729534_data = {\"mdsDat\": {\"x\": [-0.1493508141093612, -0.03549518198050527, 0.09952023477138733, -0.0009483120245849203, 0.03784531924653837, 0.028964518397131243, 0.0014552835867098332, 0.018008952112684617], \"y\": [0.06766126988565518, -0.08152063733369136, 0.11119238104910557, -0.0024186420290579383, -0.05365250830356053, -0.05266849373829761, 0.030562241263500538, -0.01915561079365377], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [18.934696197509766, 14.376127243041992, 13.987651824951172, 12.233843803405762, 11.136758804321289, 10.068611145019531, 9.644230842590332, 9.618080139160156]}, \"tinfo\": {\"Term\": [\"live\", \"smix\", \"hurt\", \"leave\", \"close\", \"rag\", \"fall\", \"disappear\", \"annoy\", \"strike\", \"realize\", \"easygoe\", \"gasp\", \"upturne\", \"perish\", \"shipboard\", \"embark\", \"unimagine\", \"unavaile\", \"feel\", \"foul\", \"reverse\", \"stunt\", \"blunt\", \"goodnature\", \"lickere\", \"remark\", \"plumb\", \"arch\", \"garnish\", \"represent\", \"soften\", \"stumble\", \"worry\", \"mean\", \"clasp\", \"charm\", \"dissemble\", \"lose\", \"pause\", \"barren\", \"continue\", \"invisible\", \"perplex\", \"insert\", \"delight\", \"touch\", \"procrastinate\", \"untrie\", \"harass\", \"anticipate\", \"close\", \"smooth\", \"shake\", \"rainswept\", \"inform\", \"goodnature\", \"reverse\", \"blunt\", \"foul\", \"leave\", \"hurt\", \"live\", \"perish\", \"spirit\", \"smix\", \"commonplace\", \"greenmottle\", \"saunter\", \"impassive\", \"unmarrie\", \"rub\", \"freeze\", \"sit\", \"impulse\", \"irritate\", \"glance\", \"dodge\", \"unattenuate\", \"tear\", \"elsie\", \"characterize\", \"shake\", \"leave\", \"close\", \"live\", \"goodnature\", \"blunt\", \"reverse\", \"stunt\", \"foul\", \"unavaile\", \"unimagine\", \"shipboard\", \"feel\", \"embark\", \"inform\", \"rainswept\", \"hurt\", \"smooth\", \"perish\", \"spirit\", \"break\", \"reserve\", \"smix\", \"anticipate\", \"harass\", \"admit\", \"bring\", \"disengage\", \"attribute\", \"forgive\", \"object\", \"frighten\", \"intimate\", \"mittene\", \"lewie\", \"sharp\", \"prepare\", \"style\", \"shre\", \"admire\", \"dim\", \"dislodge\", \"pertain\", \"receive\", \"goodnature\", \"stunt\", \"blunt\", \"foul\", \"unavaile\", \"reverse\", \"unimagine\", \"feel\", \"embark\", \"shipboard\", \"perish\", \"inform\", \"rainswept\", \"leave\", \"hurt\", \"live\", \"smooth\", \"shake\", \"close\", \"spirit\", \"smix\", \"anticipate\", \"lower\", \"adjective\", \"choose\", \"dear\", \"roll\", \"nod\", \"excite\", \"write\", \"harm\", \"slow\", \"amble\", \"marry\", \"squirm\", \"onearme\", \"smooth\", \"leave\", \"goodnature\", \"stunt\", \"reverse\", \"blunt\", \"feel\", \"foul\", \"unavaile\", \"shipboard\", \"embark\", \"unimagine\", \"perish\", \"upturne\", \"gasp\", \"easygoe\", \"inform\", \"rainswept\", \"hurt\", \"live\", \"shake\", \"close\", \"spirit\", \"break\", \"shorten\", \"smix\", \"reserve\", \"anticipate\", \"harass\", \"characterize\", \"receive\", \"skip\", \"cloud\", \"isle\", \"reign\", \"distress\", \"intend\", \"guarantee\", \"abrupt\", \"stick\", \"overlook\", \"imagine\", \"respect\", \"reserve\", \"spirit\", \"live\", \"goodnature\", \"blunt\", \"foul\", \"feel\", \"stunt\", \"reverse\", \"unimagine\", \"unavaile\", \"embark\", \"shipboard\", \"perish\", \"upturne\", \"easygoe\", \"gasp\", \"fall\", \"inform\", \"rainswept\", \"leave\", \"hurt\", \"smooth\", \"shake\", \"close\", \"break\", \"shorten\", \"smix\", \"anticipate\", \"characterize\", \"harass\", \"elsie\", \"receive\", \"lickere\", \"remark\", \"plumb\", \"arch\", \"garnish\", \"scare\", \"outer\", \"soothe\", \"shorten\", \"break\", \"live\", \"hurt\", \"goodnature\", \"reverse\", \"foul\", \"blunt\", \"feel\", \"stunt\", \"unimagine\", \"unavaile\", \"shipboard\", \"embark\", \"perish\", \"upturne\", \"gasp\", \"easygoe\", \"annoy\", \"disappear\", \"fall\", \"realize\", \"inform\", \"rainswept\", \"leave\", \"smooth\", \"shake\", \"spirit\", \"close\", \"smix\", \"reserve\", \"anticipate\", \"characterize\", \"imagine\", \"respect\", \"harass\", \"pertain\", \"tear\", \"receive\", \"elsie\", \"dislodge\", \"smix\", \"shipboard\", \"embark\", \"unimagine\", \"unavaile\", \"feel\", \"foul\", \"reverse\", \"stunt\", \"blunt\", \"goodnature\", \"inform\", \"rainswept\", \"perish\", \"upturne\", \"gasp\", \"easygoe\", \"realize\", \"disappear\", \"strike\", \"fall\", \"annoy\", \"rag\", \"break\", \"shorten\", \"soothe\", \"scare\", \"outer\", \"garnish\", \"lickere\", \"arch\", \"leave\", \"hurt\", \"live\", \"smooth\", \"shake\", \"spirit\", \"close\", \"reserve\", \"imagine\", \"anticipate\", \"characterize\", \"harass\", \"elsie\", \"pertain\", \"receive\", \"rag\", \"fall\", \"disappear\", \"annoy\", \"strike\", \"realize\", \"easygoe\", \"gasp\", \"upturne\", \"perish\", \"hurt\", \"leave\", \"goodnature\", \"stunt\", \"reverse\", \"foul\", \"blunt\", \"feel\", \"unavaile\", \"embark\", \"unimagine\", \"shipboard\", \"break\", \"shorten\", \"soothe\", \"outer\", \"garnish\", \"scare\", \"remark\", \"plumb\", \"inform\", \"rainswept\", \"live\", \"smooth\", \"shake\", \"spirit\", \"close\", \"reserve\", \"smix\", \"anticipate\", \"characterize\", \"harass\", \"imagine\", \"receive\", \"respect\", \"elsie\", \"dislodge\", \"pertain\"], \"Freq\": [2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6784809827804565, 0.6784793734550476, 0.6784590482711792, 0.6784558296203613, 0.6784418225288391, 0.6784255504608154, 0.678419291973114, 0.6783999800682068, 0.6783998608589172, 0.6783998608589172, 0.6783940196037292, 0.6783932447433472, 0.6783934831619263, 0.6783730387687683, 0.6783493757247925, 0.6783422827720642, 0.6783223748207092, 0.6782590746879578, 0.6782026290893555, 0.6776790022850037, 0.6773583292961121, 1.2884013652801514, 0.6879532933235168, 0.687616229057312, 0.4351440370082855, 0.4193723201751709, 0.07797065377235413, 0.0779576376080513, 0.07794366776943207, 0.07794138044118881, 0.0963803231716156, 0.08719431608915329, 0.09766114503145218, 0.07807781547307968, 0.07820035517215729, 0.07905817776918411, 0.6026632189750671, 0.6026568412780762, 0.602635383605957, 0.6026319265365601, 0.6026015877723694, 0.6025945544242859, 0.6025909185409546, 0.6025880575180054, 0.6025645136833191, 0.6025530099868774, 0.6025329828262329, 0.6024956107139587, 0.6024445295333862, 0.6023907661437988, 0.6023296117782593, 0.6021150350570679, 0.6107692122459412, 0.6190534234046936, 0.6120097041130066, 0.6202138066291809, 0.0692681297659874, 0.06924746930599213, 0.06924071907997131, 0.06923794746398926, 0.06923577189445496, 0.0692238137125969, 0.06922133266925812, 0.06921855360269547, 0.06922132521867752, 0.06921867281198502, 0.07528789341449738, 0.07524815946817398, 0.0774601399898529, 0.07764973491430283, 0.06935405731201172, 0.06949909776449203, 0.06931096315383911, 0.06934158504009247, 0.07023397088050842, 0.06947652250528336, 0.06938833743333817, 0.6030870079994202, 0.6030835509300232, 0.6030812859535217, 0.6030740141868591, 0.6030737161636353, 0.6030727624893188, 0.6030574440956116, 0.6030333042144775, 0.6029935479164124, 0.6029921174049377, 0.6029858589172363, 0.6029245853424072, 0.6029036045074463, 0.6028989553451538, 0.602858304977417, 0.6028115153312683, 0.6028035879135132, 0.6027295589447021, 0.6027303338050842, 0.06931008398532867, 0.06929247826337814, 0.06928610801696777, 0.06927694380283356, 0.0692734494805336, 0.06927456706762314, 0.06926773488521576, 0.06926887482404709, 0.06926554441452026, 0.06926291435956955, 0.06935437023639679, 0.07531238347291946, 0.07529021054506302, 0.08568377792835236, 0.07749287784099579, 0.08684398233890533, 0.07768476754426956, 0.0774986520409584, 0.07860219478607178, 0.06952157616615295, 0.07026908546686172, 0.06957817822694778, 0.5767345428466797, 0.5767175555229187, 0.5767087340354919, 0.5767055153846741, 0.5766997933387756, 0.5766982436180115, 0.5766957402229309, 0.5766890048980713, 0.5766751766204834, 0.5766347050666809, 0.5766299962997437, 0.5766235589981079, 0.5765859484672546, 0.5765295624732971, 0.5836758613586426, 0.5923190712928772, 0.06629428267478943, 0.06625881046056747, 0.0662565603852272, 0.066256582736969, 0.06624794006347656, 0.06624527275562286, 0.06624191254377365, 0.06623974442481995, 0.06623884290456772, 0.06623490154743195, 0.06634446233510971, 0.06628619134426117, 0.06626403331756592, 0.06626031547784805, 0.07203711569309235, 0.07199407368898392, 0.07411179691553116, 0.0829867422580719, 0.07412648946046829, 0.07515566796064377, 0.06649069488048553, 0.06632931530475616, 0.06630407273769379, 0.06721656024456024, 0.06631899625062943, 0.06646999716758728, 0.06646158546209335, 0.06637091189622879, 0.06633310765028, 0.5418792963027954, 0.5418776869773865, 0.5418689250946045, 0.5418530702590942, 0.5418482422828674, 0.5418409109115601, 0.5418293476104736, 0.5418241620063782, 0.5418238639831543, 0.5417712926864624, 0.5417205095291138, 0.5417004823684692, 0.5415564179420471, 0.5411086678504944, 0.5575202703475952, 0.06228002905845642, 0.062262311577796936, 0.06225570663809776, 0.06225383281707764, 0.062253352254629135, 0.06224941089749336, 0.06224144995212555, 0.062241677194833755, 0.06223763898015022, 0.062236666679382324, 0.06232786923646927, 0.06228817626833916, 0.062268201261758804, 0.06225704401731491, 0.062242068350315094, 0.06768473237752914, 0.06765608489513397, 0.07697974145412445, 0.06963758170604706, 0.06981389224529266, 0.0696258470416069, 0.07063564658164978, 0.06232965365052223, 0.062305618077516556, 0.06314089894294739, 0.06249905377626419, 0.062385644763708115, 0.062403954565525055, 0.06234738230705261, 0.06232864037156105, 0.523539125919342, 0.5235353708267212, 0.5235320925712585, 0.5235288143157959, 0.523518979549408, 0.5235086679458618, 0.5235069394111633, 0.5234416723251343, 0.5233252644538879, 0.5232595205307007, 1.0013669729232788, 0.5306273102760315, 0.0601731613278389, 0.060150016099214554, 0.06014661490917206, 0.060146257281303406, 0.06014302745461464, 0.06014528498053551, 0.06013794615864754, 0.06013558432459831, 0.06013349071145058, 0.06012825667858124, 0.06023627519607544, 0.060181841254234314, 0.06015755981206894, 0.06015494465827942, 0.060135193169116974, 0.06013324484229088, 0.06013293191790581, 0.06013287603855133, 0.06540129333734512, 0.0653718113899231, 0.07439301908016205, 0.06745710223913193, 0.06727718561887741, 0.06036018207669258, 0.06820137053728104, 0.06101991981267929, 0.06020955368876457, 0.06038900092244148, 0.060272715985774994, 0.060193080455064774, 0.060189709067344666, 0.06027665361762047, 0.060223087668418884, 0.060209568589925766, 0.06020890921354294, 0.060207951813936234, 0.06019430607557297, 0.9505365490913391, 0.5039116144180298, 0.5039089322090149, 0.5039008855819702, 0.5038952231407166, 0.5038830041885376, 0.5038654208183289, 0.5038540959358215, 0.5038517713546753, 0.5038489699363708, 0.5037760138511658, 0.25999847054481506, 0.24824871122837067, 0.05799862742424011, 0.0579269640147686, 0.05789729207754135, 0.05789370462298393, 0.057886652648448944, 0.05787702277302742, 0.05787729471921921, 0.05787639692425728, 0.05787617340683937, 0.05787423625588417, 0.057965803891420364, 0.05793648585677147, 0.05789962410926819, 0.057887036353349686, 0.05788661539554596, 0.057885345071554184, 0.0578802116215229, 0.05788056179881096, 0.07157901674509048, 0.06475851684808731, 0.0725027397274971, 0.06491407752037048, 0.0647500678896904, 0.05808115378022194, 0.0656772181391716, 0.057972852140665054, 0.05791718140244484, 0.05810842663049698, 0.05799814313650131, 0.058045897632837296, 0.05796384811401367, 0.05795569345355034, 0.057946570217609406, 0.5178848505020142, 0.5178720951080322, 0.5178704857826233, 0.5178666114807129, 0.5178653597831726, 0.5178621411323547, 0.5177969932556152, 0.5177920460700989, 0.5177169442176819, 0.5175267457962036, 0.524850070476532, 0.5319314002990723, 0.059517789632081985, 0.05950123816728592, 0.059498123824596405, 0.05949586629867554, 0.059495650231838226, 0.059489186853170395, 0.05948808789253235, 0.05948271229863167, 0.05948203057050705, 0.05947546660900116, 0.05957006290555, 0.05955004319548607, 0.059512220323085785, 0.05949435383081436, 0.05949006229639053, 0.05948993191123009, 0.05948285013437271, 0.05948185175657272, 0.06472393870353699, 0.06464066356420517, 0.07454510033130646, 0.06672567874193192, 0.06654854118824005, 0.05969840660691261, 0.06746156513690948, 0.05957759916782379, 0.0603608638048172, 0.059736598283052444, 0.059642743319272995, 0.05963287502527237, 0.059533555060625076, 0.05955780670046806, 0.05952610820531845, 0.059556882828474045, 0.059553004801273346, 0.05955297499895096], \"Total\": [2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.122808814048767, 1.122809648513794, 1.1228255033493042, 1.1228270530700684, 1.1228375434875488, 1.122848629951477, 1.1228523254394531, 1.1228675842285156, 1.1228673458099365, 1.1228678226470947, 1.1228724718093872, 1.1228724718093872, 1.1228727102279663, 1.1228867769241333, 1.1229054927825928, 1.1229091882705688, 1.1229240894317627, 1.1229674816131592, 1.123009204864502, 1.123393177986145, 1.1236162185668945, 2.3261444568634033, 1.6958743333816528, 1.7182122468948364, 1.1035937070846558, 1.0998181104660034, 0.9685901999473572, 0.9684811234474182, 0.968487024307251, 0.9684630036354065, 2.148319721221924, 1.5061326026916504, 2.5936408042907715, 0.9812202453613281, 1.002960205078125, 1.4218361377716064, 1.0557855367660522, 1.055793046951294, 1.0558133125305176, 1.0558170080184937, 1.055845022201538, 1.055854320526123, 1.0558546781539917, 1.0558611154556274, 1.055881381034851, 1.055891513824463, 1.0559122562408447, 1.0559511184692383, 1.0560009479522705, 1.056053638458252, 1.0561097860336304, 1.056321144104004, 1.7182122468948364, 2.148319721221924, 2.3261444568634033, 2.5936408042907715, 0.9685901999473572, 0.968487024307251, 0.9684811234474182, 0.9684826731681824, 0.9684630036354065, 0.9684195518493652, 0.9684126973152161, 0.9683971405029297, 0.9684364199638367, 0.9684012532234192, 1.0998181104660034, 1.1035937070846558, 1.5061326026916504, 1.6958743333816528, 0.9812202453613281, 1.002960205078125, 0.9861426949501038, 1.0024118423461914, 1.4218361377716064, 1.1236162185668945, 1.123393177986145, 1.0560908317565918, 1.056093454360962, 1.0560954809188843, 1.0561028718948364, 1.0561026334762573, 1.056104063987732, 1.0561178922653198, 1.0561445951461792, 1.0561796426773071, 1.0561827421188354, 1.0561882257461548, 1.056248426437378, 1.056268334388733, 1.0562753677368164, 1.0563157796859741, 1.056357502937317, 1.0563647747039795, 1.05643892288208, 1.056441068649292, 0.9685901999473572, 0.9684826731681824, 0.968487024307251, 0.9684630036354065, 0.9684195518493652, 0.9684811234474182, 0.9684126973152161, 0.9684364199638367, 0.9684012532234192, 0.9683971405029297, 0.9812202453613281, 1.0998181104660034, 1.1035937070846558, 2.148319721221924, 1.5061326026916504, 2.5936408042907715, 1.6958743333816528, 1.7182122468948364, 2.3261444568634033, 1.002960205078125, 1.4218361377716064, 1.1236162185668945, 1.0327750444412231, 1.032792329788208, 1.0328025817871094, 1.0328052043914795, 1.0328105688095093, 1.032813310623169, 1.032815933227539, 1.0328240394592285, 1.0328361988067627, 1.032881259918213, 1.0328867435455322, 1.0328930616378784, 1.032932162284851, 1.0329943895339966, 1.6958743333816528, 2.148319721221924, 0.9685901999473572, 0.9684826731681824, 0.9684811234474182, 0.968487024307251, 0.9684364199638367, 0.9684630036354065, 0.9684195518493652, 0.9683971405029297, 0.9684012532234192, 0.9684126973152161, 0.9812202453613281, 0.980961799621582, 0.9808627367019653, 0.9808558225631714, 1.0998181104660034, 1.1035937070846558, 1.5061326026916504, 2.5936408042907715, 1.7182122468948364, 2.3261444568634033, 1.002960205078125, 0.9861426949501038, 0.9860609173774719, 1.4218361377716064, 1.0024118423461914, 1.1236162185668945, 1.123393177986145, 1.056321144104004, 1.056441068649292, 1.0020116567611694, 1.0020129680633545, 1.0020232200622559, 1.0020418167114258, 1.0020489692687988, 1.0020577907562256, 1.002071738243103, 1.0020768642425537, 1.0020794868469238, 1.00214421749115, 1.0022029876708984, 1.002235770225525, 1.0024118423461914, 1.002960205078125, 2.5936408042907715, 0.9685901999473572, 0.968487024307251, 0.9684630036354065, 0.9684364199638367, 0.9684826731681824, 0.9684811234474182, 0.9684126973152161, 0.9684195518493652, 0.9684012532234192, 0.9683971405029297, 0.9812202453613281, 0.980961799621582, 0.9808558225631714, 0.9808627367019653, 0.9807533025741577, 1.0998181104660034, 1.1035937070846558, 2.148319721221924, 1.5061326026916504, 1.6958743333816528, 1.7182122468948364, 2.3261444568634033, 0.9861426949501038, 0.9860609173774719, 1.4218361377716064, 1.1236162185668945, 1.056321144104004, 1.123393177986145, 1.0561097860336304, 1.056441068649292, 0.9857754707336426, 0.9857815504074097, 0.9857852458953857, 0.9857905507087708, 0.9858009219169617, 0.9858160614967346, 0.9858182072639465, 0.9859064221382141, 0.9860609173774719, 0.9861426949501038, 2.5936408042907715, 1.5061326026916504, 0.9685901999473572, 0.9684811234474182, 0.9684630036354065, 0.968487024307251, 0.9684364199638367, 0.9684826731681824, 0.9684126973152161, 0.9684195518493652, 0.9683971405029297, 0.9684012532234192, 0.9812202453613281, 0.980961799621582, 0.9808627367019653, 0.9808558225631714, 0.9807603359222412, 0.9807553887367249, 0.9807533025741577, 0.9807659983634949, 1.0998181104660034, 1.1035937070846558, 2.148319721221924, 1.6958743333816528, 1.7182122468948364, 1.002960205078125, 2.3261444568634033, 1.4218361377716064, 1.0024118423461914, 1.1236162185668945, 1.056321144104004, 1.0022029876708984, 1.002235770225525, 1.123393177986145, 1.05643892288208, 1.056053638458252, 1.056441068649292, 1.0561097860336304, 1.0563647747039795, 1.4218361377716064, 0.9683971405029297, 0.9684012532234192, 0.9684126973152161, 0.9684195518493652, 0.9684364199638367, 0.9684630036354065, 0.9684811234474182, 0.9684826731681824, 0.968487024307251, 0.9685901999473572, 1.0998181104660034, 1.1035937070846558, 0.9812202453613281, 0.980961799621582, 0.9808627367019653, 0.9808558225631714, 0.9807659983634949, 0.9807553887367249, 0.9807629585266113, 0.9807533025741577, 0.9807603359222412, 0.9807350039482117, 0.9861426949501038, 0.9860609173774719, 0.9859064221382141, 0.9858160614967346, 0.9858182072639465, 0.9858009219169617, 0.9857754707336426, 0.9857905507087708, 2.148319721221924, 1.5061326026916504, 2.5936408042907715, 1.6958743333816528, 1.7182122468948364, 1.002960205078125, 2.3261444568634033, 1.0024118423461914, 1.0022029876708984, 1.1236162185668945, 1.056321144104004, 1.123393177986145, 1.0561097860336304, 1.05643892288208, 1.056441068649292, 0.9807350039482117, 0.9807533025741577, 0.9807553887367249, 0.9807603359222412, 0.9807629585266113, 0.9807659983634949, 0.9808558225631714, 0.9808627367019653, 0.980961799621582, 0.9812202453613281, 1.5061326026916504, 2.148319721221924, 0.9685901999473572, 0.9684826731681824, 0.9684811234474182, 0.9684630036354065, 0.968487024307251, 0.9684364199638367, 0.9684195518493652, 0.9684012532234192, 0.9684126973152161, 0.9683971405029297, 0.9861426949501038, 0.9860609173774719, 0.9859064221382141, 0.9858182072639465, 0.9858009219169617, 0.9858160614967346, 0.9857815504074097, 0.9857852458953857, 1.0998181104660034, 1.1035937070846558, 2.5936408042907715, 1.6958743333816528, 1.7182122468948364, 1.002960205078125, 2.3261444568634033, 1.0024118423461914, 1.4218361377716064, 1.1236162185668945, 1.056321144104004, 1.123393177986145, 1.0022029876708984, 1.056441068649292, 1.002235770225525, 1.0561097860336304, 1.0563647747039795, 1.05643892288208], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.6215999126434326, -3.6215999126434326, -3.6215999126434326, -3.6215999126434326, -3.6215999126434326, -3.6215999126434326, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.6217000484466553, -3.621799945831299, -3.621799945831299, -3.621799945831299, -3.6219000816345215, -3.621999979019165, -3.6226999759674072, -3.623199939727783, -2.980299949645996, -3.6077001094818115, -3.6082000732421875, -4.065700054168701, -4.102700233459473, -5.785099983215332, -5.785299777984619, -5.785399913787842, -5.7855000495910645, -5.5731000900268555, -5.673299789428711, -5.559899806976318, -5.783699989318848, -5.782100200653076, -5.771200180053711, -3.464600086212158, -3.464600086212158, -3.4646999835968018, -3.4646999835968018, -3.4646999835968018, -3.4646999835968018, -3.4647998809814453, -3.4647998809814453, -3.4647998809814453, -3.4647998809814453, -3.464900016784668, -3.464900016784668, -3.4649999141693115, -3.465100049972534, -3.4651999473571777, -3.4655001163482666, -3.4512999057769775, -3.4377999305725098, -3.449199914932251, -3.4358999729156494, -5.627999782562256, -5.628300189971924, -5.628399848937988, -5.628399848937988, -5.628499984741211, -5.628600120544434, -5.628699779510498, -5.628699779510498, -5.628699779510498, -5.628699779510498, -5.5447001457214355, -5.545199871063232, -5.516200065612793, -5.513800144195557, -5.626800060272217, -5.62470006942749, -5.627399921417236, -5.6269001960754395, -5.614200115203857, -5.625, -5.626299858093262, -3.436500072479248, -3.436500072479248, -3.436500072479248, -3.4365999698638916, -3.4365999698638916, -3.4365999698638916, -3.4365999698638916, -3.4365999698638916, -3.4367001056671143, -3.4367001056671143, -3.4367001056671143, -3.436800003051758, -3.436800003051758, -3.436800003051758, -3.4368999004364014, -3.437000036239624, -3.437000036239624, -3.4370999336242676, -3.4370999336242676, -5.599999904632568, -5.600299835205078, -5.600399971008301, -5.600500106811523, -5.600500106811523, -5.600500106811523, -5.600599765777588, -5.600599765777588, -5.6006999015808105, -5.6006999015808105, -5.599400043487549, -5.517000198364258, -5.517199993133545, -5.387899875640869, -5.488399982452393, -5.374499797821045, -5.485899925231934, -5.48829984664917, -5.4741997718811035, -5.5970001220703125, -5.586299896240234, -5.596099853515625, -3.3471999168395996, -3.3473000526428223, -3.3473000526428223, -3.3473000526428223, -3.3473000526428223, -3.3473000526428223, -3.3473000526428223, -3.3473000526428223, -3.347399950027466, -3.347399950027466, -3.347399950027466, -3.347399950027466, -3.3475000858306885, -3.347599983215332, -3.3352999687194824, -3.3206000328063965, -5.510499954223633, -5.511099815368652, -5.511099815368652, -5.511099815368652, -5.511199951171875, -5.511300086975098, -5.511300086975098, -5.51140022277832, -5.51140022277832, -5.51140022277832, -5.509799957275391, -5.5106000900268555, -5.511000156402588, -5.511000156402588, -5.4274001121521, -5.427999973297119, -5.399099826812744, -5.285999774932861, -5.398900032043457, -5.3850998878479, -5.507599830627441, -5.510000228881836, -5.51039981842041, -5.496699810028076, -5.510200023651123, -5.507900238037109, -5.507999897003174, -5.509399890899658, -5.509900093078613, -3.3155999183654785, -3.3155999183654785, -3.315700054168701, -3.315700054168701, -3.315700054168701, -3.315700054168701, -3.315700054168701, -3.315700054168701, -3.315700054168701, -3.3157999515533447, -3.3159000873565674, -3.315999984741211, -3.316200017929077, -3.3171000480651855, -3.2871999740600586, -5.479000091552734, -5.479300022125244, -5.479400157928467, -5.479499816894531, -5.479499816894531, -5.479499816894531, -5.479700088500977, -5.479700088500977, -5.479700088500977, -5.479700088500977, -5.478300094604492, -5.478899955749512, -5.4791998863220215, -5.479400157928467, -5.479599952697754, -5.3958001136779785, -5.396200180053711, -5.267099857330322, -5.367400169372559, -5.364799976348877, -5.367499828338623, -5.353099822998047, -5.4781999588012695, -5.478600025177002, -5.4653000831604, -5.475500106811523, -5.47730016708374, -5.4770002365112305, -5.478000164031982, -5.478300094604492, -3.2492001056671143, -3.2492001056671143, -3.2492001056671143, -3.249300003051758, -3.249300003051758, -3.249300003051758, -3.249300003051758, -3.2493999004364014, -3.2495999336242676, -3.249799966812134, -2.6006999015808105, -3.23580002784729, -5.412600040435791, -5.413000106811523, -5.413099765777588, -5.413099765777588, -5.413099765777588, -5.413099765777588, -5.4131999015808105, -5.4131999015808105, -5.413300037384033, -5.413400173187256, -5.411600112915039, -5.412499904632568, -5.412899971008301, -5.412899971008301, -5.413300037384033, -5.413300037384033, -5.413300037384033, -5.413300037384033, -5.3292999267578125, -5.329800128936768, -5.200500011444092, -5.298399925231934, -5.301000118255615, -5.4095001220703125, -5.287399768829346, -5.398600101470947, -5.4120001792907715, -5.408999919891357, -5.410999774932861, -5.412300109863281, -5.412300109863281, -5.410900115966797, -5.411799907684326, -5.4120001792907715, -5.4120001792907715, -5.4120001792907715, -5.412300109863281, -2.609800100326538, -3.2444000244140625, -3.2444000244140625, -3.2444000244140625, -3.2444000244140625, -3.2444000244140625, -3.244499921798706, -3.244499921798706, -3.244499921798706, -3.244499921798706, -3.2446999549865723, -3.906100034713745, -3.952399969100952, -5.406400203704834, -5.407599925994873, -5.408100128173828, -5.408199787139893, -5.408299922943115, -5.4085001945495605, -5.4085001945495605, -5.4085001945495605, -5.4085001945495605, -5.4085001945495605, -5.406899929046631, -5.407400131225586, -5.408100128173828, -5.408299922943115, -5.408299922943115, -5.408299922943115, -5.408400058746338, -5.408400058746338, -5.196000099182129, -5.29610013961792, -5.183199882507324, -5.293700218200684, -5.296199798583984, -5.404900074005127, -5.2820000648498535, -5.406799793243408, -5.407800197601318, -5.4045000076293945, -5.406400203704834, -5.405600070953369, -5.4070000648498535, -5.407100200653076, -5.407299995422363, -3.2142999172210693, -3.2142999172210693, -3.2142999172210693, -3.214400053024292, -3.214400053024292, -3.214400053024292, -3.2144999504089355, -3.2144999504089355, -3.214600086212158, -3.2149999141693115, -3.2009999752044678, -3.1875998973846436, -5.377799987792969, -5.3780999183654785, -5.3780999183654785, -5.378200054168701, -5.378200054168701, -5.378300189971924, -5.378300189971924, -5.378399848937988, -5.378399848937988, -5.378499984741211, -5.3769001960754395, -5.377299785614014, -5.377900123596191, -5.378200054168701, -5.378300189971924, -5.378300189971924, -5.378399848937988, -5.378399848937988, -5.293900012969971, -5.295199871063232, -5.152699947357178, -5.263500213623047, -5.26609992980957, -5.374800205230713, -5.252500057220459, -5.376800060272217, -5.363699913024902, -5.374100208282471, -5.375699996948242, -5.375899791717529, -5.377500057220459, -5.377099990844727, -5.377699851989746, -5.377099990844727, -5.377200126647949, -5.377200126647949], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1604000329971313, 1.1604000329971313, 1.1604000329971313, 1.1604000329971313, 1.1604000329971313, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1603000164031982, 1.1601999998092651, 1.1601999998092651, 1.160099983215332, 1.160099983215332, 1.159999966621399, 1.1598999500274658, 1.1586999893188477, 1.1581000089645386, 1.0734000205993652, 0.761900007724762, 0.7483999729156494, 0.7335000038146973, 0.699999988079071, -0.8553000092506409, -0.855400025844574, -0.8555999994277954, -0.8555999994277954, -1.440000057220459, -1.184999942779541, -1.6151000261306763, -0.8669000267982483, -0.8873000144958496, -1.2252999544143677, 1.3789000511169434, 1.3789000511169434, 1.3788000345230103, 1.3788000345230103, 1.3788000345230103, 1.3787000179290771, 1.3787000179290771, 1.3787000179290771, 1.3787000179290771, 1.378600001335144, 1.378600001335144, 1.378499984741211, 1.3783999681472778, 1.3782000541687012, 1.378100037574768, 1.377500057220459, 0.9053000211715698, 0.6953999996185303, 0.6043999791145325, 0.5088000297546387, -0.6983000040054321, -0.6984000205993652, -0.6984999775886536, -0.6985999941825867, -0.6985999941825867, -0.6987000107765198, -0.6987000107765198, -0.6988000273704529, -0.6988000273704529, -0.6988000273704529, -0.7419999837875366, -0.7458999752998352, -1.027899980545044, -1.1440999507904053, -0.7099999785423279, -0.7297999858856201, -0.7156000137329102, -0.7315000295639038, -1.0683000087738037, -0.8436999917030334, -0.8447999954223633, 1.4067000150680542, 1.4067000150680542, 1.4067000150680542, 1.4067000150680542, 1.4067000150680542, 1.4067000150680542, 1.4067000150680542, 1.406599998474121, 1.406499981880188, 1.406499981880188, 1.406499981880188, 1.4062999486923218, 1.4062999486923218, 1.4062000513076782, 1.4061000347137451, 1.406000018119812, 1.406000018119812, 1.4057999849319458, 1.4057999849319458, -0.6703000068664551, -0.6704000234603882, -0.6704999804496765, -0.6705999970436096, -0.6705999970436096, -0.6707000136375427, -0.6707000136375427, -0.6707000136375427, -0.6707000136375427, -0.6707000136375427, -0.6826000213623047, -0.7142999768257141, -0.7179999947547913, -1.2547999620437622, -1.000100016593933, -1.4297000169754028, -1.1162999868392944, -1.1318000555038452, -1.4206000566482544, -0.7020999789237976, -1.0404000282287598, -0.8148999810218811, 1.5183000564575195, 1.5183000564575195, 1.5183000564575195, 1.5183000564575195, 1.5182000398635864, 1.5182000398635864, 1.5182000398635864, 1.5182000398635864, 1.5182000398635864, 1.5181000232696533, 1.5181000232696533, 1.5180000066757202, 1.517899990081787, 1.517799973487854, 1.0343999862670898, 0.8126000165939331, -0.5807999968528748, -0.5812000036239624, -0.5812000036239624, -0.5812000036239624, -0.5813000202178955, -0.5813999772071838, -0.5813999772071838, -0.5813999772071838, -0.5813999772071838, -0.5814999938011169, -0.5929999947547913, -0.5935999751091003, -0.5938000082969666, -0.5939000248908997, -0.6248000264167786, -0.6287999749183655, -0.9107999801635742, -1.3411999940872192, -1.0422999858856201, -1.3314000368118286, -0.6126999855041504, -0.5982000231742859, -0.5985000133514404, -0.9508000016212463, -0.6147000193595886, -0.7265999913215637, -0.7264999747276306, -0.6662999987602234, -0.6669999957084656, 1.580199956893921, 1.580199956893921, 1.580199956893921, 1.5801000595092773, 1.5801000595092773, 1.5801000595092773, 1.5800000429153442, 1.5800000429153442, 1.5800000429153442, 1.5799000263214111, 1.579699993133545, 1.5795999765396118, 1.579200029373169, 1.5778000354766846, 0.6575999855995178, -0.5493000149726868, -0.5494999885559082, -0.5494999885559082, -0.5494999885559082, -0.5496000051498413, -0.5497000217437744, -0.5497000217437744, -0.5497000217437744, -0.5497999787330627, -0.5497999787330627, -0.5615000128746033, -0.5618000030517578, -0.5620999932289124, -0.5622000098228455, -0.5623999834060669, -0.5931000113487244, -0.597000002861023, -1.1339999437332153, -0.8791000247001648, -0.995199978351593, -1.0110000371932983, -1.2994999885559082, -0.5663999915122986, -0.5666999816894531, -0.9193999767303467, -0.6941999793052673, -0.6342999935150146, -0.6955999732017517, -0.6347000002861023, -0.6352999806404114, 1.6628999710083008, 1.6628999710083008, 1.6628999710083008, 1.6628999710083008, 1.6628999710083008, 1.6627999544143677, 1.6627999544143677, 1.662600040435791, 1.6621999740600586, 1.6619999408721924, 1.344099998474121, 1.252500057220459, -0.4828999936580658, -0.4830999970436096, -0.4832000136375427, -0.4832000136375427, -0.4832000136375427, -0.4832000136375427, -0.48330000042915344, -0.48330000042915344, -0.48330000042915344, -0.48339998722076416, -0.49480000138282776, -0.49540001153945923, -0.49570000171661377, -0.4957999885082245, -0.4959999918937683, -0.4959999918937683, -0.4959999918937683, -0.4959999918937683, -0.5266000032424927, -0.5304999947547913, -1.0672999620437622, -0.9286999702453613, -0.9445000290870667, -0.5145999789237976, -1.2338000535964966, -0.8528000116348267, -0.5166000127792358, -0.6277999877929688, -0.5679000020027161, -0.516700029373169, -0.516700029373169, -0.6294000148773193, -0.5688999891281128, -0.5687000155448914, -0.569100022315979, -0.5687999725341797, -0.5692999958992004, 1.9361000061035156, 1.6856000423431396, 1.6856000423431396, 1.6855000257492065, 1.6855000257492065, 1.6855000257492065, 1.6854000091552734, 1.6854000091552734, 1.6854000091552734, 1.6854000091552734, 1.6850999593734741, 0.8966000080108643, 0.8468999862670898, -0.4896000027656555, -0.49050000309944153, -0.4909999966621399, -0.4909999966621399, -0.4909999966621399, -0.4912000000476837, -0.4912000000476837, -0.4912000000476837, -0.4912000000476837, -0.4912000000476837, -0.4950999915599823, -0.49559998512268066, -0.4959999918937683, -0.49619999527931213, -0.49619999527931213, -0.49619999527931213, -0.49619999527931213, -0.49630001187324524, -1.0628000497817993, -0.8077999949455261, -1.2383999824523926, -0.9240999817848206, -0.9397000074386597, -0.5101000070571899, -1.2283999919891357, -0.5113999843597412, -0.5120999813079834, -0.623199999332428, -0.5633000135421753, -0.6241000294685364, -0.5637000203132629, -0.5641999840736389, -0.564300000667572, 1.7029999494552612, 1.7029000520706177, 1.7029000520706177, 1.7029000520706177, 1.7029000520706177, 1.7029000520706177, 1.7027000188827515, 1.7027000188827515, 1.7023999691009521, 1.701799988746643, 1.2872999906539917, 0.9455999732017517, -0.4480000138282776, -0.448199987411499, -0.44830000400543213, -0.44830000400543213, -0.44830000400543213, -0.44839999079704285, -0.44839999079704285, -0.44839999079704285, -0.44850000739097595, -0.44859999418258667, -0.4650999903678894, -0.46540001034736633, -0.4659000039100647, -0.4661000072956085, -0.4661000072956085, -0.4661000072956085, -0.46619999408721924, -0.46619999408721924, -0.4912000000476837, -0.4959999918937683, -1.207900047302246, -0.8938000202178955, -0.909600019454956, -0.4799000024795532, -1.1988999843597412, -0.4814000129699707, -0.817799985408783, -0.5928000211715698, -0.5325999855995178, -0.5943999886512756, -0.48190000653266907, -0.5342000126838684, -0.4819999933242798, -0.5339000225067139, -0.5342000126838684, -0.5343000292778015]}, \"token.table\": {\"Topic\": [5, 4, 3, 3, 4, 8, 1, 6, 3, 1, 7, 6, 3, 2, 1, 4, 1, 1, 2, 5, 2, 1, 4, 1, 3, 8, 3, 3, 1, 5, 2, 8, 2, 7, 4, 8, 7, 3, 7, 2, 3, 6, 8, 2, 7, 2, 5, 1, 4, 6, 8, 5, 2, 2, 1, 5, 3, 1, 2, 5, 2, 4, 8, 3, 6, 2, 5, 6, 1, 4, 4, 1, 3, 4, 3, 4, 6, 5, 1, 8, 1, 3, 6, 3, 1, 8, 8, 3, 5, 6, 1, 5, 5, 7, 4, 2, 2, 6, 1, 2, 3, 7, 6, 3, 2, 5, 4, 7, 1, 4, 1, 6, 5, 4, 5, 8, 1, 7, 3, 2, 1, 2, 7, 7, 2, 1, 8, 1, 4], \"Freq\": [0.9979274272918701, 0.9682488441467285, 0.9466866254806519, 0.946888267993927, 0.9681603312492371, 1.0196170806884766, 0.889983594417572, 1.0144143104553223, 0.9468774795532227, 0.8905730843544006, 1.0325384140014648, 1.0140520334243774, 0.946885883808136, 0.946681797504425, 0.8905890583992004, 0.9682392477989197, 0.8905919790267944, 0.42989590764045715, 0.42989590764045715, 0.9979910850524902, 0.9471620321273804, 0.8905730843544006, 0.9682368040084839, 0.8905439376831055, 0.9466491937637329, 1.0196222066879272, 0.9468840956687927, 0.9466426968574524, 0.890576958656311, 0.9979552030563354, 0.9470135569572449, 1.0195177793502808, 0.946871280670166, 1.0326298475265503, 0.9682267308235168, 1.0196243524551392, 1.0325922966003418, 0.946877658367157, 1.0325639247894287, 0.947100043296814, 0.9468640089035034, 1.0144035816192627, 1.0195106267929077, 0.9470483660697937, 1.0324283838272095, 0.9471552968025208, 0.9979325532913208, 0.890160322189331, 0.9682077169418335, 0.6639521718025208, 0.6639521718025208, 0.9978018403053284, 0.9471338391304016, 0.9470760822296143, 0.8905469179153442, 0.9979464411735535, 0.9468400478363037, 0.8905729055404663, 0.9470669627189636, 0.9979808926582336, 0.4654800593852997, 0.4654800593852997, 0.4654800593852997, 0.9468058347702026, 1.0144298076629639, 0.3855583965778351, 0.3855583965778351, 0.3855583965778351, 0.8905771374702454, 0.9682650566101074, 0.9681544303894043, 0.8906008005142212, 0.9468086361885071, 0.9682291746139526, 0.9468764066696167, 0.9680594801902771, 1.0143858194351196, 0.9978603720664978, 0.8905767798423767, 1.0191391706466675, 0.8905617594718933, 0.9465762376785278, 1.014419674873352, 0.9467469453811646, 0.8904977440834045, 1.0196434259414673, 1.0196112394332886, 0.946574330329895, 0.9979623556137085, 1.0144234895706177, 0.8906235694885254, 0.9975939393043518, 0.9977692365646362, 1.0325446128845215, 0.968231737613678, 0.9471003413200378, 0.9471371173858643, 1.0143879652023315, 0.5820002555847168, 0.5820002555847168, 0.946800947189331, 1.0326341390609741, 1.0141360759735107, 0.9467228055000305, 0.9470942616462708, 0.9979923963546753, 0.9681655168533325, 0.7033159136772156, 0.5896663069725037, 0.5896663069725037, 0.8906229138374329, 1.0142951011657715, 0.997048556804657, 0.9681177735328674, 0.9979248046875, 1.019614338874817, 0.8906103372573853, 1.0325429439544678, 0.9467291235923767, 0.9469215869903564, 0.8905321359634399, 0.9469688534736633, 1.032610297203064, 1.0326175689697266, 0.9471086859703064, 0.8904646635055542, 1.0194076299667358, 0.890609085559845, 0.9682191610336304], \"Term\": [\"abrupt\", \"adjective\", \"admire\", \"admit\", \"amble\", \"annoy\", \"anticipate\", \"arch\", \"attribute\", \"barren\", \"blunt\", \"break\", \"bring\", \"characterize\", \"charm\", \"choose\", \"clasp\", \"close\", \"close\", \"cloud\", \"commonplace\", \"continue\", \"dear\", \"delight\", \"dim\", \"disappear\", \"disengage\", \"dislodge\", \"dissemble\", \"distress\", \"dodge\", \"easygoe\", \"elsie\", \"embark\", \"excite\", \"fall\", \"feel\", \"forgive\", \"foul\", \"freeze\", \"frighten\", \"garnish\", \"gasp\", \"glance\", \"goodnature\", \"greenmottle\", \"guarantee\", \"harass\", \"harm\", \"hurt\", \"hurt\", \"imagine\", \"impassive\", \"impulse\", \"insert\", \"intend\", \"intimate\", \"invisible\", \"irritate\", \"isle\", \"leave\", \"leave\", \"leave\", \"lewie\", \"lickere\", \"live\", \"live\", \"live\", \"lose\", \"lower\", \"marry\", \"mean\", \"mittene\", \"nod\", \"object\", \"onearme\", \"outer\", \"overlook\", \"pause\", \"perish\", \"perplex\", \"pertain\", \"plumb\", \"prepare\", \"procrastinate\", \"rag\", \"realize\", \"receive\", \"reign\", \"remark\", \"represent\", \"reserve\", \"respect\", \"reverse\", \"roll\", \"rub\", \"saunter\", \"scare\", \"shake\", \"shake\", \"sharp\", \"shipboard\", \"shorten\", \"shre\", \"sit\", \"skip\", \"slow\", \"smix\", \"smooth\", \"smooth\", \"soften\", \"soothe\", \"spirit\", \"squirm\", \"stick\", \"strike\", \"stumble\", \"stunt\", \"style\", \"tear\", \"touch\", \"unattenuate\", \"unavaile\", \"unimagine\", \"unmarrie\", \"untrie\", \"upturne\", \"worry\", \"write\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 6, 8, 7, 1, 5, 4]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1291399460634618563754729534\", ldavis_el1291399460634618563754729534_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1291399460634618563754729534\", ldavis_el1291399460634618563754729534_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1291399460634618563754729534\", ldavis_el1291399460634618563754729534_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1     -0.149351  0.067661       1        1  18.934696\n",
              "2     -0.035495 -0.081521       2        1  14.376127\n",
              "5      0.099520  0.111192       3        1  13.987652\n",
              "7     -0.000948 -0.002419       4        1  12.233844\n",
              "6      0.037845 -0.053653       5        1  11.136759\n",
              "0      0.028965 -0.052668       6        1  10.068611\n",
              "4      0.001455  0.030562       7        1   9.644231\n",
              "3      0.018009 -0.019156       8        1   9.618080, topic_info=         Term      Freq     Total Category  logprob  loglift\n",
              "27       live  2.000000  2.000000  Default  30.0000  30.0000\n",
              "120      smix  1.000000  1.000000  Default  29.0000  29.0000\n",
              "32       hurt  1.000000  1.000000  Default  28.0000  28.0000\n",
              "72      leave  2.000000  2.000000  Default  27.0000  27.0000\n",
              "25      close  2.000000  2.000000  Default  26.0000  26.0000\n",
              "..        ...       ...       ...      ...      ...      ...\n",
              "68    receive  0.059558  1.056441   Topic8  -5.3771  -0.5342\n",
              "39    respect  0.059526  1.002236   Topic8  -5.3777  -0.4820\n",
              "121     elsie  0.059557  1.056110   Topic8  -5.3771  -0.5339\n",
              "94   dislodge  0.059553  1.056365   Topic8  -5.3772  -0.5342\n",
              "67    pertain  0.059553  1.056439   Topic8  -5.3772  -0.5343\n",
              "\n",
              "[381 rows x 6 columns], token_table=      Topic      Freq       Term\n",
              "term                            \n",
              "109       5  0.997927     abrupt\n",
              "102       4  0.968249  adjective\n",
              "35        3  0.946687     admire\n",
              "59        3  0.946888      admit\n",
              "69        4  0.968160      amble\n",
              "...     ...       ...        ...\n",
              "97        2  0.947109   unmarrie\n",
              "89        1  0.890465     untrie\n",
              "53        8  1.019408    upturne\n",
              "48        1  0.890609      worry\n",
              "108       4  0.968219      write\n",
              "\n",
              "[129 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 6, 8, 7, 1, 5, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh7j0bEnQG6C",
        "colab_type": "code",
        "outputId": "6dc0fbc8-2a63-40be-8d0b-4c50ea307fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "mallet_path = 'mallet-2.0.8/bin/mallet' # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-6c9e5b10ded3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mallet-2.0.8/bin/mallet'\u001b[0m \u001b[0;31m# update this path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1880\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/2b20d2_corpus.txt --output /tmp/2b20d2_corpus.mallet' returned non-zero exit status 127."
          ]
        }
      ]
    }
  ]
}